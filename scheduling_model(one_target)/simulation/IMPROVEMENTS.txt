# ğŸ”„ Simulation æ–‡ä»¶å¤¹æ”¹è¿›æ€»ç»“

**æ›´æ–°æ—¶é—´**: 2026-02-01  
**æ”¹è¿›èŒƒå›´**: simulation æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰ Python è„šæœ¬  
**ç›®çš„**: æ”¯æŒåŠ¨æ€ä¼ æ„Ÿå™¨é…ç½®ï¼Œæ— éœ€ä¿®æ”¹ä»¿çœŸè„šæœ¬

---

## ğŸ“ æ”¹è¿›å†…å®¹

### 1ï¸âƒ£ quick_simulate.py

**ä¿®æ”¹ä½ç½®**: ç¬¬ 40-42 è¡Œ

**ä¹‹å‰**:
```python
model = CartpoleModel(obs_dim=6, act_dim=env.act_dim)
alg = DQN(model, gamma=0.95, lr=0.001)
agent = CartpoleAgent(alg, act_dim=env.act_dim, e_greed=0.0, e_greed_decrement=0.0)
```

**ä¹‹å**:
```python
obs_dim = 6  # å›ºå®šï¼š[x, y, x_prev, y_prev, last_action, lost_flag]
act_dim = env.act_dim  # ä»ç¯å¢ƒè‡ªåŠ¨è¯»å–ä¼ æ„Ÿå™¨æ•°é‡

model = CartpoleModel(obs_dim=obs_dim, act_dim=act_dim)
alg = DQN(model, gamma=0.95, lr=0.001)
agent = CartpoleAgent(alg, act_dim=act_dim, e_greed=0.0, e_greed_decrement=0.0)
```

**ä¼˜ç‚¹**: ä½¿ä»£ç æ›´æ¸…æ™°ï¼Œact_dim çš„æ¥æºæ›´æ˜ç¡®

---

### 2ï¸âƒ£ verify_environment.py

**ä¿®æ”¹ä½ç½®**: ç¬¬ 134-142 è¡Œ

**ä¹‹å‰**:
```python
print("\n[2] Creating environment...")
env = Env(seed=42)
print("    [OK] Environment created")

print("\n[3] Creating agent...")
model = CartpoleModel(obs_dim=6, act_dim=2)
alg = DQN(model, gamma=0.95, lr=0.001)
agent = CartpoleAgent(alg, act_dim=2, e_greed=0.0, e_greed_decrement=0.0)
```

**ä¹‹å**:
```python
print("\n[2] Creating environment...")
env = Env(seed=42)
print("    [OK] Environment created")
print(f"    [INFO] Sensors detected: {len(env.sensors)}, act_dim: {env.act_dim}")

print("\n[3] Creating agent...")
obs_dim = 6  # å›ºå®šï¼š[x, y, x_prev, y_prev, last_action, lost_flag]
act_dim = env.act_dim  # ä»ç¯å¢ƒè‡ªåŠ¨è¯»å–ä¼ æ„Ÿå™¨æ•°é‡
model = CartpoleModel(obs_dim=obs_dim, act_dim=act_dim)
alg = DQN(model, gamma=0.95, lr=0.001)
agent = CartpoleAgent(alg, act_dim=act_dim, e_greed=0.0, e_greed_decrement=0.0)
```

**ä¼˜ç‚¹**: 
- åŠ¨æ€æ£€æµ‹ä¼ æ„Ÿå™¨æ•°é‡è€Œä¸æ˜¯ç¡¬ç¼–ç  2
- è¾“å‡ºè¯Šæ–­ä¿¡æ¯æ˜¾ç¤ºæ£€æµ‹åˆ°çš„ä¼ æ„Ÿå™¨æ•°é‡
- éªŒè¯æ—¶ä¼šæ˜¾ç¤ºå®é™…çš„é…ç½®

---

### 3ï¸âƒ£ simulate_and_visualize.py

**ä¿®æ”¹å†…å®¹ 1**: é‡å†™ print_summary å‡½æ•°ï¼ˆç¬¬ 263-305 è¡Œï¼‰

**ä¹‹å‰**:
- ç¡¬ç¼–ç äº† "Radar 0" å’Œ "Radar 1"
- åªèƒ½å¤„ç† 2 ä¸ªä¼ æ„Ÿå™¨
- æ— æ³•è‡ªåŠ¨é€‚é…æ–°çš„ä¼ æ„Ÿå™¨é…ç½®

**ä¹‹å**:
```python
def print_summary(recorder, env=None):
    """æ‰“å°ä»¿çœŸæ‘˜è¦ï¼ˆæ”¯æŒåŠ¨æ€ä¼ æ„Ÿå™¨æ•°é‡ï¼‰"""
    # ...
    num_sensors = int(np.max(actions)) + 1  # ä»actionä¸­æ¨æ–­ä¼ æ„Ÿå™¨æ•°é‡
    if env is not None:
        num_sensors = env.act_dim  # å¦‚æœæœ‰envï¼Œä¼˜å…ˆä½¿ç”¨envçš„act_dim
    
    print(f"\nSensor usage ({num_sensors} sensors total):")
    
    # ä¼ æ„Ÿå™¨ä½¿ç”¨ç»Ÿè®¡
    for sensor_id in range(num_sensors):
        count = np.sum(actions == sensor_id)
        percentage = count / total_steps * 100 if total_steps > 0 else 0
        print(f"  Sensor {sensor_id}: {count} times ({percentage:.1f}%)")
    
    # ... æ£€æµ‹ç»Ÿè®¡ ...
```

**ä¼˜ç‚¹**:
- è‡ªåŠ¨é€‚é…ä»»ä½•æ•°é‡çš„ä¼ æ„Ÿå™¨
- ä½¿ç”¨å¾ªç¯éå†æ‰€æœ‰ä¼ æ„Ÿå™¨
- è¾“å‡ºæ›´æ¸…æ™°çš„æ ¼å¼

**ä¿®æ”¹å†…å®¹ 2**: æ›´æ–° print_summary çš„è°ƒç”¨ï¼ˆç¬¬ 357 è¡Œï¼‰

**ä¹‹å‰**:
```python
print_summary(recorder)
```

**ä¹‹å**:
```python
print_summary(recorder, env=env)
```

**ä¼˜ç‚¹**: å°†ç¯å¢ƒå¯¹è±¡ä¼ é€’ç»™å‡½æ•°ï¼Œä»¥ä¾¿è·å–å‡†ç¡®çš„ä¼ æ„Ÿå™¨æ•°é‡

---

### 4ï¸âƒ£ launcher.py

**ä¿®æ”¹ä½ç½®**: ç¬¬ 10-16 è¡Œ

**æ·»åŠ **:
```python
print("ğŸ’¡ TIP: ä¿®æ”¹ Envir.py ä¸­çš„ sensors åˆ—è¡¨å³å¯æ·»åŠ /ä¿®æ”¹ä¼ æ„Ÿå™¨")
print("   æ‰€æœ‰ä»¿çœŸè„šæœ¬éƒ½ä¼šè‡ªåŠ¨é€‚é…æ–°çš„ä¼ æ„Ÿå™¨é…ç½®")
```

**ä¼˜ç‚¹**: æé†’ç”¨æˆ·å…³äºåŠ¨æ€ä¼ æ„Ÿå™¨é…ç½®çš„åŠŸèƒ½

---

## âœ… æµ‹è¯•ç»“æœ

è¿è¡Œ `verify_environment.py` åçš„è¾“å‡ºï¼š

```
[2] Creating environment...
    [OK] Environment created
    [INFO] Sensors detected: 3, act_dim: 3

[3] Creating agent...
    [OK] Agent created

[4] Running 10-step simulation...
    [OK] Simulation successful (total reward: -12.00)

============================================================
[SUCCESS] All functionality tests passed!
============================================================
```

âœ… ç¡®è®¤ä¿®æ”¹å·¥ä½œæ­£å¸¸ï¼

---

## ğŸ¯ ç°åœ¨çš„å·¥ä½œæµç¨‹

### æ·»åŠ æ–°ä¼ æ„Ÿå™¨

1. **æ‰“å¼€** [Envir.py](../Envir.py)
2. **ä¿®æ”¹** `self.sensors` åˆ—è¡¨ï¼Œä¾‹å¦‚æ·»åŠ ç¬¬ 4 ä¸ªä¼ æ„Ÿå™¨
3. **ä¿å­˜** æ–‡ä»¶
4. **è¿è¡Œä»¿çœŸ**:
   ```bash
   cd simulation
   python quick_simulate.py
   ```
5. âœ… **å®Œæˆ** - æ‰€æœ‰è„šæœ¬è‡ªåŠ¨é€‚é…æ–°é…ç½®ï¼

### æ— éœ€ä¿®æ”¹çš„é¡¹ç›®

âœ… quick_simulate.py - è‡ªåŠ¨è¯»å– act_dim  
âœ… simulate_and_visualize.py - è‡ªåŠ¨é€‚é…ä¼ æ„Ÿå™¨æ•°é‡  
âœ… verify_environment.py - æ˜¾ç¤ºå®é™…æ£€æµ‹åˆ°çš„ä¼ æ„Ÿå™¨  
âœ… launcher.py - é€šè¿‡è°ƒç”¨å…¶ä»–è„šæœ¬è‡ªåŠ¨é€‚é…  

---

## ğŸ“Š ä¿®æ”¹å¯¹æ¯”

| é¡¹ç›® | ä¿®æ”¹å‰ | ä¿®æ”¹å |
|------|--------|--------|
| **ä¼ æ„Ÿå™¨æ•°é‡** | ç¡¬ç¼–ç  2 | åŠ¨æ€è¯»å– |
| **è„šæœ¬å…¼å®¹æ€§** | ä»…é™ 2 ä¼ æ„Ÿå™¨ | ä»»æ„æ•°é‡ |
| **è¯Šæ–­ä¿¡æ¯** | æ— æ³•æ˜¾ç¤ºå®é™…é…ç½® | æ˜¾ç¤ºæ£€æµ‹åˆ°çš„ä¼ æ„Ÿå™¨ |
| **ä»£ç ç»´æŠ¤** | æ·»åŠ ä¼ æ„Ÿå™¨éœ€ä¿®æ”¹å¤šä¸ªè„šæœ¬ | ä»…éœ€ä¿®æ”¹ Envir.py |

---

## ğŸ’¡ æŠ€æœ¯ç»†èŠ‚

### ä¸ºä»€ä¹ˆè¿™æ ·è®¾è®¡ï¼Ÿ

1. **obs_dim å›ºå®šä¸º 6**: è§‚å¯Ÿç©ºé—´ç»“æ„å›ºå®š [x, y, x_prev, y_prev, last_action, lost_flag]
2. **act_dim åŠ¨æ€è·å–**: åŠ¨ä½œç©ºé—´ç­‰äºä¼ æ„Ÿå™¨æ•°é‡ï¼Œä» Envir.py è‡ªåŠ¨è¯»å–
3. **print_summary åŠ¨æ€ç»Ÿè®¡**: éå†æ‰€æœ‰å¯èƒ½çš„ action å€¼ç¡®å®šä¼ æ„Ÿå™¨æ•°é‡

### å‘åå…¼å®¹æ€§

âœ… æ‰€æœ‰ä¿®æ”¹éƒ½æ˜¯å‘åå…¼å®¹çš„  
âœ… 2 ä¸ªä¼ æ„Ÿå™¨çš„æ—§æ¨¡å‹ä»ç„¶å¯ä»¥æ­£å¸¸ä½¿ç”¨  
âœ… æ·»åŠ æ–°ä¼ æ„Ÿå™¨åéœ€è¦é‡æ–°è®­ç»ƒæ¨¡å‹  

---

## ğŸš€ ä¸‹ä¸€æ­¥

### ç”¨æˆ·æ“ä½œ

1. ä¿®æ”¹ [Envir.py](../Envir.py) ä¸­çš„ `self.sensors` åˆ—è¡¨
2. è¿è¡Œ `python simulation/verify_environment.py` éªŒè¯
3. è¿è¡Œ `python simulation/quick_simulate.py` æµ‹è¯•
4. å¦‚éœ€è¦ï¼Œè¿è¡Œ `python train(2).py` é‡æ–°è®­ç»ƒæ¨¡å‹

### å¯¹å¼€å‘è€…

æ‰€æœ‰ä»¿çœŸè„šæœ¬ç°åœ¨éƒ½éµå¾ªè¿™ä¸ªæ¨¡å¼ï¼š
```python
env = Env()
obs_dim = 6              # å›ºå®š
act_dim = env.act_dim    # åŠ¨æ€
# ... ä½¿ç”¨ act_dim åˆå§‹åŒ–æ¨¡å‹ ...
```

---

## ğŸ“‹ æ–‡ä»¶ä¿®æ”¹æ¸…å•

- âœ… `simulation/quick_simulate.py` - ä¼˜åŒ–åˆå§‹åŒ–é€»è¾‘
- âœ… `simulation/verify_environment.py` - åŠ¨æ€æ£€æµ‹+æ˜¾ç¤ºä¼ æ„Ÿå™¨ä¿¡æ¯
- âœ… `simulation/simulate_and_visualize.py` - é‡å†™ print_summary æ”¯æŒåŠ¨æ€ä¼ æ„Ÿå™¨
- âœ… `simulation/launcher.py` - æ·»åŠ æç¤ºä¿¡æ¯

---

### 5ï¸âƒ£ quick_simulate.pyï¼ˆé¢å¤–æ”¹è¿›ï¼‰

**ä¿®æ”¹ä½ç½® 1**: ç¬¬ 112-125 è¡Œï¼ˆé¢œè‰²é…ç½®ï¼‰

**ä¹‹å‰**: ç¡¬ç¼–ç  `colors = ['#FF6B6B', '#4ECDC4']`  
**ä¹‹å**: åŠ¨æ€è°ƒè‰²æ¿ + å¾ªç¯ç”Ÿæˆé¢œè‰²

```python
color_palette = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8', '#F7DC6F']
colors = []
for i in range(len(env.sensors)):
    if i < len(color_palette):
        colors.append(color_palette[i])
    else:
        colors.append(f'#{rand_module.randint(0, 0xFFFFFF):06x}')
```

**ä¿®æ”¹ä½ç½® 2**: ç¬¬ 190-203 è¡Œï¼ˆç»Ÿè®¡è¾“å‡ºï¼‰

**ä¹‹å‰**:
```python
usage_0 = np.sum(actions == 0)
usage_1 = np.sum(actions == 1)
print(f"\nRadar usage:")
print(f"  Radar 0: {usage_0} times ...")
print(f"  Radar 1: {usage_1} times ...")
```

**ä¹‹å**:
```python
num_sensors = len(env.sensors)
print(f"\nSensor usage ({num_sensors} sensors total):")

for sensor_id in range(num_sensors):
    usage = np.sum(actions == sensor_id)
    if usage > 0:
        print(f"  Sensor {sensor_id}: {usage} times ...")
        detect_count = np.sum(detects[actions == sensor_id])
        print(f"    Detection rate: {detect_count/usage*100:.1f}%")
```

---

### 6ï¸âƒ£ simulate_and_visualize.pyï¼ˆé¢å¤–æ”¹è¿›ï¼‰

**ä¿®æ”¹ä½ç½® 1**: ç¬¬ 161-176 è¡Œï¼ˆé¢œè‰²é…ç½®ï¼‰

åŒ quick_simulate.py çš„åŠ¨æ€é¢œè‰²é…ç½®

**ä¿®æ”¹ä½ç½® 2**: ç¬¬ 240-250 è¡Œï¼ˆåŠ¨ä½œåºåˆ—å›¾è¡¨ï¼‰

**ä¹‹å‰**: ç¡¬ç¼–ç  `ax.set_yticklabels(['Radar 0', 'Radar 1'])`

**ä¹‹å**:
```python
num_sensors = len(env.sensors)
sensor_ticks = list(range(num_sensors))
sensor_labels = [f'Sensor {i}' for i in range(num_sensors)]
ax.set_yticks(sensor_ticks)
ax.set_yticklabels(sensor_labels)
```

**ä¼˜ç‚¹**: å›¾è¡¨è‡ªåŠ¨é€‚é…ä»»æ„æ•°é‡çš„ä¼ æ„Ÿå™¨

---

## âœ… å®Œæ•´æµ‹è¯•ç»“æœ

### verify_environment.py è¾“å‡º
```
[INFO] Sensors detected: 3, act_dim: 3
[OK] Agent created
[OK] Simulation successful (total reward: -12.00)
[SUCCESS] All functionality tests passed!
```

### quick_simulate.py è¾“å‡º
```
Running simulation...
  Episode ended at step 27

Sensor usage (3 sensors total):
  Sensor 1: 21 times (77.8%)
    Detection rate: 95.2%
  Sensor 2: 6 times (22.2%)
    Detection rate: 66.7%
```

âœ… æ‰€æœ‰è„šæœ¬éƒ½æ­£ç¡®æ”¯æŒ 3 ä¸ªä¼ æ„Ÿå™¨ï¼

---

## ğŸ“‹ å®Œæ•´çš„æ–‡ä»¶ä¿®æ”¹æ¸…å•

- âœ… `simulation/quick_simulate.py` - 2å¤„ä¿®æ”¹
  - é¢œè‰²é…ç½®
  - ç»Ÿè®¡è¾“å‡º
  
- âœ… `simulation/verify_environment.py` - 1å¤„ä¿®æ”¹
  - æ˜¾ç¤ºä¼ æ„Ÿå™¨ä¿¡æ¯
  
- âœ… `simulation/simulate_and_visualize.py` - 3å¤„ä¿®æ”¹
  - print_summary å‡½æ•°
  - é¢œè‰²é…ç½®
  - åŠ¨ä½œåºåˆ—å›¾è¡¨
  
- âœ… `simulation/launcher.py` - 1å¤„ä¿®æ”¹
  - æç¤ºä¿¡æ¯

### 7ï¸âƒ£ simulate_and_visualize.pyï¼ˆbug ä¿®å¤ï¼‰

**ä¿®æ”¹ä½ç½®**: ç¬¬ 258-274 è¡Œï¼ˆæ£€æµ‹ç‡å›¾è¡¨ï¼‰

**é—®é¢˜**: å½“ episode é•¿åº¦ < 10 æ­¥æ—¶ï¼Œ`np.convolve` è¿”å›ç©ºæ•°ç»„ï¼Œå¯¼è‡´ matplotlib æŠ¥é”™

**ä¹‹å‰**:
```python
detect_rate = np.convolve(detects.astype(float), np.ones(10)/10, mode='valid')
window_times = times[9:]
ax.plot(window_times, detect_rate * 100, 'g-', linewidth=2, ...)
```

**ä¹‹å**:
```python
if len(detects) >= 10:
    # é•¿ episodeï¼š10 æ­¥æ»‘åŠ¨çª—å£
    detect_rate = np.convolve(detects.astype(float), np.ones(10)/10, mode='valid')
    window_times = times[9:]
    ax.plot(window_times, detect_rate * 100, 'g-', linewidth=2, ...)
    ax.set_title('Detection Rate (Sliding Window)')
else:
    # çŸ­ episodeï¼šæ˜¾ç¤ºæ€»ä½“æ£€æµ‹ç‡
    overall_detect_rate = np.mean(detects) * 100 if len(detects) > 0 else 0
    ax.axhline(y=overall_detect_rate, color='g', linestyle='-', ...)
    ax.set_title('Detection Rate')
```

**ä¼˜ç‚¹**: è‡ªåŠ¨é€‚é…ä»»æ„é•¿åº¦çš„ episode

---

### 8ï¸âƒ£ simulate_and_visualize.pyï¼ˆå†…å­˜ä¼˜åŒ–ï¼‰

**ä¿®æ”¹ä½ç½®**: ç¬¬ 374-402 è¡Œï¼ˆå›¾è¡¨ç»˜åˆ¶å’Œä¿å­˜ï¼‰

**é—®é¢˜**: å¤š episode è¿è¡Œæ—¶ï¼Œmatplotlib åˆ›å»ºå¤šä¸ª figure ä½†æœªå…³é—­ï¼Œå¯¼è‡´å†…å­˜æ³„æ¼å’Œ RuntimeWarning

**ä¹‹å‰**:
```python
plot_trajectory(recorder, env, save_path=traj_path)
plot_statistics(recorder, env=env, save_path=stat_path)
...
fig, ax = plt.subplots(figsize=(10, 6))
...
plt.savefig(compare_path, dpi=150, bbox_inches='tight')
```

**ä¹‹å**:
```python
fig_traj = plot_trajectory(recorder, env, save_path=traj_path)
plt.close(fig_traj)

fig_stat = plot_statistics(recorder, env=env, save_path=stat_path)
plt.close(fig_stat)
...
fig, ax = plt.subplots(figsize=(10, 6))
...
plt.savefig(compare_path, dpi=150, bbox_inches='tight')
plt.close(fig)
```

**ä¼˜ç‚¹**: 
- åŠæ—¶é‡Šæ”¾å†…å­˜
- æ¶ˆé™¤ matplotlib RuntimeWarning
- æ”¯æŒå¤§é‡ episodes çš„è¿è¡Œ

---

## âœ… æœ€ç»ˆéªŒè¯ç»“æœ

### 3 Episode å®Œæ•´è¿è¡Œï¼ˆæ— ä»»ä½•è­¦å‘Šï¼‰
```
Episode 1: 32 steps, 279.76 reward
Episode 2: 28 steps, 281.06 reward  
Episode 3: 24 steps, 242.99 reward

âœ… æ— ä»»ä½•è­¦å‘Šæˆ–é”™è¯¯
âœ… æ‰€æœ‰å›¾è¡¨æˆåŠŸä¿å­˜
âœ… å†…å­˜æ­£å¸¸é‡Šæ”¾
```

---

**æ€»ä¿®æ”¹æ•°**: 8å¤„ä»£ç æ”¹è¿›

